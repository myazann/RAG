[MPT-7B]
repo_id = mosaicml/mpt-7b-chat
context_length = 2048

[FALCON-7B]
repo_id = tiiuae/falcon-7b-instruct
context_length = 2048

[GPT4ALL-13B-GPTQ]
repo_id = TheBloke/GPT4All-13B-Snoozy-SuperHOT-8K-GPTQ
basename = gpt4all-snoozy-13b-superhot-8k-GPTQ-4bit-128g.no-act.order
context_length = 2048

[VICUNA-7B-v1.5-GPTQ]
repo_id = TheBloke/vicuna-7B-v1.5-GPTQ
context_length = 4096

[VICUNA-13B-v1.5-GPTQ]
repo_id = TheBloke/vicuna-13B-v1.5-GPTQ
context_length = 4096

[LLAMA2-7B-HF]
repo_id = meta-llama/Llama-2-7b-chat-hf
context_length = 4096

[LLAMA2-7B-32K]
repo_id = togethercomputer/Llama-2-7B-32K-Instruct
context_length = 32768

[LLAMA2-7B-GPTQ]
repo_id = TheBloke/Llama-2-7b-Chat-GPTQ
basename = model
context_length = 4096

[LLAMA2-13B-GPTQ]
repo_id = TheBloke/Llama-2-13B-chat-GPTQ
basename = model
context_length = 4096

[STABLE-BELUGA-7B-GPTQ]
repo_id = TheBloke/StableBeluga-7B-GPTQ
basename = gptq_model-4bit-128g
context_length = 4096

[STABLE-BELUGA-13B-GPTQ]
repo_id = TheBloke/StableBeluga-13B-GPTQ
basename = gptq_model-4bit-128g
context_length = 4096

[OPEN-CHAT-GPTQ]
repo_id = TheBloke/OpenChat-v3.2-GPTQ
basename = gptq_model-4bit-128g
context_length = 4096

[BTLM-3B-8K]
repo_id = cerebras/btlm-3b-8k-base
context_length = 8192

[CLAUDE-V1]
repo_id = claude-1.2
context_length = 100000

[CLAUDE-V2]
repo_id = claude-2.0
context_length = 100000

[LUNA-UNCENSORED]
repo_id = TheBloke/Luna-AI-Llama2-Uncensored-GPTQ
basename = gptq_model-4bit-128g
context_length = 4096